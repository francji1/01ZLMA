{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01ZLMA/blob/main/code/01ZLMA_ex01_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Necessary theory recap from Lectures 01-03\n",
        "\n",
        "Let's consider (m1):\n",
        "  1. realization $(y_i,\\ldots,y_n)$ of $iid$ random variables $Y_1,\\ldots,Y_n$ with probability density function $f(y;\\theta;\\phi)$ from an exponential family of probability distributions\n",
        "  $$f(y;\\theta;\\phi) = exp\\left(\\frac{y \\theta - b(\\theta)}{a(\\phi)} - c(y,\\phi)\\right),$$\n",
        "  where conditions of regularity are fulfilled (one dimensional case, i.e. $y_i,\\theta_i \\in R, a(\\phi) >0, \\phi >0)$.\n",
        "  2. Regression matrix $X$ and vector of unknown parameters $\\beta$, linear predictor $Î· = X \\beta$\n",
        "  3. A link function $g(x)$\n",
        "  $$\\eta_i = g(\\mu_i) = x_i^T \\beta, \\ \\text{where} \\ \\mu_i = E[Y_i] \\ \\ i = 1,\\ldots,n$$\n",
        "\n",
        "The dispersion $a(\\phi)$ is typically known. If not, we take it as nuisance parameter.\n",
        "\n",
        "Link function satisfying $g(\\mu_i) = \\theta_i$ is called canonical."
      ],
      "metadata": {
        "id": "qTVa3p_xajzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For $b(\\theta) \\in C^2$ we showed:\n",
        "$$E[Y] = b'(\\theta) $$\n",
        "$$V[Y] = a(\\phi) b''(\\theta) $$\n",
        "and defined variance function $v(\\mu) = \\frac{\\partial \\mu}{\\partial \\theta}$, i.e. $V[Y] = a(\\phi) v(\\mu)$"
      ],
      "metadata": {
        "id": "utLSxIoual59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relations:\n",
        "\n",
        "$$\n",
        "\\beta \\xrightarrow[]{\\eta_i = x_i^T\\beta} \\eta\n",
        "\\xrightarrow[]{\\mu_i = g^{-1}(\\eta_i)}  \\mu\n",
        "\\xrightarrow[]{\\theta_i = (b')^{-1}(\\mu_i)}  \\theta\n",
        "$$\n",
        "\n",
        "Inverse relatiions\n",
        "$$\n",
        "\\eta_i\n",
        "\\xleftarrow[]{}  \\mu\n",
        "\\xleftarrow[]{}  \\theta\n",
        "$$"
      ],
      "metadata": {
        "id": "eABp9H3vaqTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma**:\n",
        "Let Y have an exponential type distribution with density given in m1, where $b(\\theta)$ is 2 times continuously differentiable, then there exists a everywhere finite moment generating function $M_Y(t) = E[e^{ty}]$ that is 2 times differentiable at 0 and it holds:\n",
        "* $E[Y] = b'(\\theta)$\n",
        "* $V[Y] = a(\\phi) b''(\\theta)$"
      ],
      "metadata": {
        "id": "dtoTlhUCaugR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HW 01\n",
        "\n",
        "Compute $E[Y]$, $V[Y]$, and $v(Y)$ by the help of moment generating function theory for the following disributions:\n",
        "* Normal: $N(\\mu,\\sigma^2)$\n",
        "* Poisson: $Poi(\\lambda)$\n",
        "* Bernoulli: $Ber(p)$\n",
        "\n",
        "  $f(y,p) = p^y(1-p)^{1-y}$\n",
        "* Gamma: $\\Gamma[a,p]$\n",
        "\n",
        " $ {\\displaystyle f(y,a,p)={\\frac {a ^{p }}{\\Gamma (p)}}y^{p -1}e^{-a y}}$\n",
        "* Inverse: Gaussian $IG[\\mu, \\lambda]$\n",
        "\n",
        "  ${\\displaystyle f(y;\\mu ,\\lambda )={\\sqrt {\\frac {\\lambda }{2\\pi y^{3}}}}\\exp {\\biggl (}-{\\frac {\\lambda (y-\\mu )^{2}}{2\\mu ^{2}y}}{\\biggr )}}$\n",
        "\n",
        "\n",
        "Questions:\n",
        "* Which distributions can fulfill homoscedasticity?\n",
        "* For which distribution the variance increases with the square of the mean value?\n",
        "* Does exists a distribution, where $V[Y] = k \\cdot \\mu$ ?"
      ],
      "metadata": {
        "id": "ZLt-CUGxayjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "Pm5EiBTpa2Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Normal: $N(\\mu,$ $\\sigma^2)$\n",
        "\n",
        "$f(y, \\mu, \\sigma^2) = \\frac{1}{\\sqrt {{(2\\pi )} \\sigma^2}}  {\\mathrm {e}}^-{\\frac{{\\left(y- \\mu \\right)}^{T}{\\left( y-\\mu \\right)}}{\\sigma^2}} = {\\mathrm {e}}^{\\frac{y \\mu - \\frac{\\mu^2}{2}}{\\sigma^2} - \\left(  \\frac{y^2}{2\\sigma^2} + \\frac{1}{2} ln(2 \\pi \\sigma^2) \\right)}$\n",
        "\n",
        "* $\\theta = \\mu  \\Rightarrow b(\\theta) = \\frac{\\mu^2}{2} = \\frac{\\theta^2}{2}$\n",
        "* $\\phi = \\sigma^2 \\Rightarrow a(\\phi) = \\sigma^2 = \\phi$\n",
        "* $E[Y] = b'(\\theta) = \\mu$\n",
        "* $V[Y] = a(\\phi) b''(\\theta)= \\sigma^2 $\n",
        "\n",
        "Linear variance function: $v(\\mu) = \\frac{\\partial \\mu}{\\partial \\theta} = 1$"
      ],
      "metadata": {
        "id": "P-BcntiAa7Lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Poisson: $Poi(\\lambda)$\n",
        "\n",
        "$f(y,\\lambda) = \\frac{\\lambda^y e^{-\\lambda}}{y!} = exp[y ln(\\lambda)  -\\lambda -ln(y!)] $\n",
        "\n",
        "* $\\theta = ln(\\lambda) \\Rightarrow b(\\theta) = \\lambda = e^{\\theta}$\n",
        "*  $E[Y] = b'(\\theta) = e^{\\theta} = \\lambda$\n",
        "* $V[Y] = b''(\\theta)=e^{\\theta} = \\lambda$\n",
        "\n",
        "Linear variance function: $v(\\lambda) = \\frac{\\partial \\lambda}{\\partial \\theta} = e^{\\theta} = \\lambda$"
      ],
      "metadata": {
        "id": "4-vgk1Lia-ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bernoulli: $Ber(p)$\n",
        "\n",
        "  $f(y,p) = p^y(1-p)^{1-y} = \\textrm{exp}[y \\textrm{ln}(p) + (1-y)\\textrm{ln}(1-p)] = \\textrm{exp}[y \\textrm{ln}(\\frac{p}{1-p}) + \\textrm{ln}(1-p)]$\n",
        "\n",
        "* $\\theta = \\textrm{ln}(\\frac{p}{1-p}) \\Rightarrow p = \\frac{e^{\\theta}}{1+e^{\\theta}}$ and $b(\\theta) = -\\textrm{ln}(1-p) = -\\textrm{ln}(\\frac{1}{1+e^{\\theta}}) = \\textrm{ln}(1+e^{\\theta})$\n",
        "* $ E[Y] =  b'(\\theta) = \\frac{e^{\\theta}}{1+e^{\\theta}} = p$\n",
        "* $ V[Y] = b''(\\theta) = \\frac{e^{\\theta}(1+e^{\\theta})-e^{2\\theta}}{(1+e^{\\theta})^2} = \\frac{e^{\\theta}}{(1+e^{\\theta})^2} = \\frac{p}{1+\\frac{p}{1-p}} = p(p-1)$\n",
        "\n",
        "Linear variance function: $v(p) = \\frac{\\partial p}{\\partial \\theta} = p(1-p)$"
      ],
      "metadata": {
        "id": "Rq_uHpl7bDUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gamma: $\\Gamma[a,p]$\n",
        "\n",
        " $ f(y;a,p)={\\frac {a ^{p }}{\\Gamma (p)}y^{p -1}e^{-a y}} = |subst. a = \\frac{p}{q}| = (\\frac{p}{q})^p \\frac{y^{p-1}}{\\Gamma(p)} \\textrm{exp}(-\\frac{p}{q}y) = f(y;q,p)  $\n",
        "\n",
        "Then\n",
        " $$\n",
        " \\begin{aligned}\n",
        " f(y;q,p) &= \\biggl(\\frac{p}{q} \\biggr)^p \\frac{y^{p-1}}{\\Gamma(p)} \\textrm{exp}\\biggl(-\\frac{p}{q}y \\biggr) = \\textrm{exp}\\biggl[-\\frac{p}{q}y+p\\textrm{ln}(p)-p\\textrm{ln}(q)+(p-1)\\textrm{ln}(y)-\\textrm{ln}(\\Gamma(p))\\biggr] \\\\\n",
        " &= \\textrm{exp}\\biggl[\\frac{-\\frac{1}{q}y-\\textrm{ln}(q)}{\\frac{1}{p}}+p\\textrm{ln}(p)+(p-1)\\textrm{ln}(y)-\\textrm{ln}(\\Gamma(p))\\biggr]\n",
        " \\end{aligned}\n",
        " $$\n",
        "\n",
        "\n",
        "* $\\theta = -\\frac{1}{q}  \\Rightarrow b(\\theta) = \\textrm{ln}(q) = \\textrm{ln}(-\\frac{1}{\\theta}) = -\\textrm{ln}(-\\theta) $\n",
        "* $\\phi = \\frac{1}{p} \\Rightarrow a(\\phi) = \\phi$\n",
        "* $E[Y] = b'(\\theta) = -\\frac{1}{\\theta}$\n",
        "* $V[Y] = a(\\phi) b''(\\theta)= \\phi \\frac{1}{\\theta^2}$\n",
        "\n",
        "Linear variance function: $v(q) = \\frac{\\partial q}{\\partial \\theta} = \\frac{1}{\\theta^2}$"
      ],
      "metadata": {
        "id": "M5lSTH9xbJOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inverse Gaussian: $IG[\\mu, \\lambda]$\n",
        "\n",
        "  $$\n",
        "  \\begin{aligned}\n",
        "  f(y;\\mu ,\\lambda )&={\\sqrt {\\frac {\\lambda }{2\\pi y^{3}}}}\\exp {\\biggl (}-{\\frac {\\lambda (y-\\mu )^{2}}{2\\mu ^{2}y}{\\biggr )}} = \\exp\\biggl[-\\lambda\\Bigl(\\frac{y}{2\\mu^2}-\\frac{1}{\\mu}+\\frac{1}{2y}\\Bigr)+\\frac{1}{2}\\textrm{ln}\\Bigl(\\frac{\\lambda}{2\\pi y^3}\\Bigr)\\biggr]= \\\\\n",
        "  & =\\exp\\Biggl[\\frac{y\\cdot\\Bigl(\\frac{1}{2\\mu^2}\\Bigr)-\\frac{1}{\\mu}}{-\\frac{1}{\\lambda}}+\\frac{1}{2}\\Bigl(-\\frac{\\lambda}{y}+\\textrm{ln}(\\frac{\\lambda}{2\\pi y^{3}})\\Bigr)\\Biggr]\n",
        "  \\end{aligned}\n",
        "  $$\n",
        "\n",
        "* $\\theta = \\frac{1}{2\\mu^2}  \\Rightarrow b(\\theta) = \\frac{1}{\\mu} = \\sqrt{2\\theta}$\n",
        "* $\\phi = \\lambda \\Rightarrow a(\\phi) = -\\frac{1}{\\lambda}=-\\frac{1}{\\phi}$\n",
        "* $E[Y] = b'(\\theta) = \\frac{2}{2\\sqrt{2\\theta}}=\\frac{1}{\\sqrt{2\\theta}}=\\mu$\n",
        "* $V[Y] = a(\\phi) b''(\\theta)= -\\frac{1}{\\phi}(-\\frac{1}{(\\sqrt{2\\theta})^3})= \\frac{1}{\\phi(\\sqrt{2\\theta})^3}=\\frac{\\mu^3}{\\lambda} $\n",
        "\n",
        "Linear variance function: $v(\\mu) = \\frac{\\partial \\mu}{\\partial \\theta} = \\mu^3$"
      ],
      "metadata": {
        "id": "fVhi4NjAcRxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Beta: $\\text{Beta}$$[\\alpha,$ $\\beta]$\n",
        "\n",
        " $ \\text{Beta}(y; \\alpha, \\beta) = \\frac{y^{\\alpha-1}(1-y)^{\\beta-1}}{B(\\alpha, \\beta)}$, where $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$\n",
        "\n",
        "  $$\n",
        "  \\begin{aligned}\n",
        "  \\text{Beta}(y; \\alpha, \\beta) = \\frac{y^{\\alpha-1}(1-y)^{\\beta-1}}{B(\\alpha, \\beta)} = \\textrm{exp}[(\\alpha-1)\\textrm{ln}(y)+(\\beta-1)\\textrm{ln}(1-y)-\\textrm{ln}(B(\\alpha, \\beta))]\n",
        "  \\end{aligned}\n",
        "  $$\n",
        "\n",
        "\n",
        "In this case we will use more general definition of exponential family of densities.\n",
        "$$\n",
        "$$\n",
        "An exponential family of densities for an n-dimensional random vector $Y = (Y_1, \\ldots, Y_n)$ in $\\mathbb{R}^n$ is defined by a probability density function $f(y;\\omega)$ with parameter $\\omega$ in the parametric space $\\Omega \\subseteq \\mathbb{R}^s$. Each density in this family takes the form\n",
        "\n",
        "$$\n",
        "f(y;\\omega) = \\exp\\left( \\sum_{i=1}^s \\eta_i(\\omega)T_i(y) - A(\\omega) \\right) h(y),\n",
        "$$\n",
        "\n",
        "where $T_i$ is a sufficient statistic for $\\omega$, $\\eta_i$ is known as the natural parameter, $A$ is the log-partition function, and $h$ is a base measure on $Y$. The expected value and variance of $T_i$ are given by the first and second derivatives of $A$ with respect to $\\eta_i$, respectively, for $i = 1,2,\\ldots,s$.\n",
        "\n",
        "$$\n",
        "$$\n",
        "\n",
        "The Beta distribution is a member of the 2-parametric exponential family of densities and it satisfies the previous definition for $s=2$. That means\n",
        "* $\\omega = (\\alpha, \\beta)$\n",
        "* $T_1(y) = \\textrm{ln}(y)$, $T_2(y) = \\textrm{ln}(1-y)$\n",
        "* $\\eta_1(\\alpha, \\beta) = \\alpha-1$, $\\eta_2(\\alpha, \\beta) = \\beta-1$\n",
        "* $A(\\alpha, \\beta)=\\textrm{ln}(B(\\alpha, \\beta))$\n",
        "* $h(y)= \\mathbb{I}_{y\\in(0,1)}$\n",
        "* $$E[T_1(Y)] = \\frac{\\partial A}{\\partial \\eta_1}=\\frac{\\partial \\textrm{ln}(B(\\alpha, \\beta))}{\\partial(\\alpha-1)} = \\frac{\\partial \\textrm{ln}(B(\\alpha, \\beta))}{\\partial\\alpha}\\frac{\\partial \\alpha}{\\partial(\\alpha-1)} = \\frac{\\partial \\textrm{ln}(B(\\alpha, \\beta))}{\\partial\\alpha} = \\frac{\\partial}{\\partial \\alpha}[\\textrm{ln}\\Gamma(\\alpha)+\\textrm{ln}\\Gamma(\\beta)-\\textrm{ln}\\Gamma(\\alpha+\\beta)]=\\frac{\\partial}{\\partial \\alpha}\\textrm{ln}\\Gamma(\\alpha)-\\frac{\\partial}{\\partial \\alpha}\\textrm{ln}\\Gamma(\\alpha+\\beta) = \\psi(\\alpha)-\\psi(\\alpha + \\beta),$$\n",
        "where $\\psi$ is digamma function\n",
        "* $E[T_2(Y)] = \\frac{\\partial A}{\\partial \\eta_2}=\\psi(\\beta)-\\psi(\\alpha + \\beta)$, where $\\psi$ is digamma function\n",
        "* $V[T_1(Y)] = \\frac{\\partial^2 A}{\\partial \\eta_1^2}= \\psi^{(1)}(\\alpha)-\\psi^{(1)}(\\alpha + \\beta) $, where $\\psi^{(1)}$ is trigamma function\n",
        "* $V[T_2(Y)] = \\frac{\\partial^2 A}{\\partial \\eta_1^2}= \\psi^{(1)}(\\beta)-\\psi^{(1)}(\\alpha + \\beta) $, where $\\psi^{(1)}$ is trigamma function\n"
      ],
      "metadata": {
        "id": "HBzKH-LqdFJY"
      }
    }
  ]
}